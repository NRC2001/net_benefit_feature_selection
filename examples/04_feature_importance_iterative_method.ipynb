{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import dca_fs_tools as dcat\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An iterative method based on full model feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement an itterative method of feature selection based on net benefit which is similar to a forward-stepwise selection method except that the order of inclusion of feature is fixed by their importance in a full model.\n",
    "\n",
    "Features are itteratively included and models re-fit. At each step the net-benefit (or mean net benefit over all threshold probabilities) is calculated. The optimum set of features is that which maximizes net benefit.\n",
    "\n",
    "This example is based on the scikit learn make_classification synthetic data set described in [00_synthetic_data_description.ipynb](./00_synthetic_data_description.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1000\n",
    "\n",
    "df_train, df_test, ind_var_names = dcat.make_class_dataset(n_sample = n_sample,\n",
    "                                       n_features = 5,\n",
    "                                       n_redundant = 0,\n",
    "                                       random_state = 1001,\n",
    "                                       n_informative = 4,\n",
    "                                       n_clusters_per_class = 1,\n",
    "                                       n_classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the logistic regression model (this could be any type of model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10**18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for performing the itterative approach. The steps are described in code comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_dcafs(train_data, test_data, model, harms_dict, dependent=\"y\", nb_thresholds = [0.9, 0.6]):\n",
    "\n",
    "    independent = harms_dict.keys()\n",
    "\n",
    "    #identify feature imporrtances with the regularization path (other methods are possible)\n",
    "    skl_path = dcat.skl_reg_path(train_data,\n",
    "                                 test_data,\n",
    "                                log_space_min = 0,\n",
    "                                log_space_max = 3.5,\n",
    "                                log_space_steps = 64,\n",
    "                                nb_thresholds = nb_thresholds)\n",
    "\n",
    "    # order featuures by l1 regularization\n",
    "    feature_imp = (skl_path.loc[:, independent]==0).astype(int).sum(axis=0).sort_values().index.to_list()\n",
    "\n",
    "    # itterate through the features fitting a model for each subset\n",
    "    # Calculate the mean net benefit for each model select the modle\n",
    "    # that maximizes mean net benefit\n",
    "    thresholds = np.asarray(nb_thresholds)\n",
    "    nb_threshs_cols = [\"net_benefit_pt_\"+ str(i) for i, j in enumerate(nb_thresholds)]\n",
    "\n",
    "    out = pd.DataFrame(columns = [\"features\", \"mnb\"] + nb_threshs_cols)\n",
    "    for i in range(len(independent)):\n",
    "        model_features = feature_imp[0:i+1]\n",
    "        \n",
    "        # fit full model\n",
    "        model.fit(train_data[model_features], train_data[dependent])\n",
    "\n",
    "        # Make predictions on the test set:\n",
    "        pred = model.predict_proba(test_data[model_features])\n",
    "\n",
    "        # mnb\n",
    "        mnb = dcat.mean_net_benefit(test_data[dependent], pred[:, 1], n_thresh=100)['mnb']\n",
    "\n",
    "        # net benefit at specific thresholds\n",
    "        nb_thresh = dcat.net_benefit(test_data[dependent], pred[:, 1] , thresholds = thresholds)[1]\n",
    "        \n",
    "\n",
    "        #Include test harms\n",
    "        harm = sum([test_harms[i] for i in model_features]) \n",
    "\n",
    "        mnb = mnb - harm\n",
    "\n",
    "        nb_thresh = [i - harm for i in nb_thresh]\n",
    "\n",
    "\n",
    "        nb_thresh_out = pd.Series(dict(zip(nb_threshs_cols, nb_thresh)))\n",
    "\n",
    "        out.loc[i] = pd.concat([\n",
    "            pd.Series({\"features\": model_features, \"mnb\": mnb}),\n",
    "            nb_thresh_out\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mnb</th>\n",
       "      <th>net_benefit p_t=0.8</th>\n",
       "      <th>net_benefit p_t=0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[x1]</td>\n",
       "      <td>0.209659</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[x1, x4]</td>\n",
       "      <td>0.219324</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.32375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[x1, x4, x3]</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[x1, x4, x3, x0]</td>\n",
       "      <td>0.172733</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[x1, x4, x3, x0, x2]</td>\n",
       "      <td>0.142756</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.2575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               features       mnb net_benefit p_t=0.8 net_benefit p_t=0.2\n",
       "0                  [x1]  0.209659                0.03              0.3475\n",
       "1              [x1, x4]  0.219324               0.105             0.32375\n",
       "2          [x1, x4, x3]    0.1786                0.09               0.285\n",
       "3      [x1, x4, x3, x0]  0.172733                0.08             0.28875\n",
       "4  [x1, x4, x3, x0, x2]  0.142756               0.055              0.2575"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_harms = {\"x0\": 0.0, \"x1\": 0.015, \"x2\": 0.03, \"x3\": 0.045, \"x4\": 0.06 }\n",
    "\n",
    "forward_selection = feature_importance_dcafs(df_train, df_test, logreg, test_harms, nb_thresholds = [0.8, 0.2])\n",
    "\n",
    "# Save for later comparison to other methods\n",
    "\n",
    "with open('../data/forward_selection.pkl', 'wb') as f:\n",
    "    pickle.dump(forward_selection, f)\n",
    "\n",
    "forward_selection.rename(columns = {\"net_benefit_pt_0\": \"net_benefit p_t=0.8\",\n",
    "                                    \"net_benefit_pt_1\": \"net_benefit p_t=0.2\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the maximum net benefit occurs when features $\\{ x1, x4\\}$ are selected, in this case independently of probability thresholds we tested or the use of mean net benefit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
