{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # for feature scaling\n",
    "from sklearn.model_selection import train_test_split  # for train/test split\n",
    "import matplotlib.pyplot as plt  #For representation\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import l1_min_c  # for L1 regluarization path\n",
    "\n",
    "# Example code for calculating accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from statkit.decision import net_benefit\n",
    "from statkit.decision import net_benefit\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "import dca_fs_tools as dcat\n",
    "import dca_fs as dcafs\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1000\n",
    "\n",
    "df_train, df_test, ind_var_names = dcat.make_class_dataset(n_sample = n_sample,\n",
    "                                       n_features = 5,\n",
    "                                       n_redundant = 0,\n",
    "                                       random_state = 1001,\n",
    "                                       n_informative = 4,\n",
    "                                       n_clusters_per_class = 1,\n",
    "                                       n_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10**18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mnb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[x0, x1, x2, x3, x4]</td>\n",
       "      <td>0.15341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[x0, x1, x2, x4]</td>\n",
       "      <td>0.195265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[x0, x1, x4]</td>\n",
       "      <td>0.22011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[x1, x4]</td>\n",
       "      <td>0.224445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[x1]</td>\n",
       "      <td>0.213858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               features       mnb\n",
       "0  [x0, x1, x2, x3, x4]   0.15341\n",
       "1      [x0, x1, x2, x4]  0.195265\n",
       "2          [x0, x1, x4]   0.22011\n",
       "3              [x1, x4]  0.224445\n",
       "4                  [x1]  0.213858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit full model\n",
    "#logreg.fit(df_train[ind_var_names], df_train[\"y\"])\n",
    "\n",
    "# define feature harms\n",
    "\n",
    "test_harms = {\"x0\": 0.0, \"x1\": 0.015, \"x2\": 0.03, \"x3\": 0.045, \"x4\": 0.06 }\n",
    " \n",
    "dependent = \"y\"\n",
    "\n",
    "#identify feature importances\n",
    "#skl_path = dcat.skl_reg_path(df_train,\n",
    "#                            log_space_min = 0,\n",
    "#                            log_space_max = 3.5,\n",
    "#                            log_space_steps = 64)\n",
    "\n",
    "# order featuures by l1 regularization\n",
    "#feature_imp = (skl_path.loc[:, ind_var_names]==0).astype(int).sum(axis=0).sort_values().index.to_list()\n",
    "\n",
    "# itterate through the features fitting a model for each subset\n",
    "# Calculate the mean net benefit for each model select the modle\n",
    "# that maximizes mean net benefit\n",
    "\n",
    "features_left = test_harms.keys()\n",
    "\n",
    "# Initialize with full model\n",
    "out = pd.DataFrame(columns = [\"features\", \"mnb\"])\n",
    "logreg.fit(df_test[features_left], df_test[\"y\"])\n",
    "pred = logreg.predict_proba(df_test[features_left])\n",
    "mnb = dcat.mean_net_benefit(df_test[dependent], pred[:, 1], n_thresh=100)['mnb']\n",
    "harm = sum([test_harms[i] for i in features_left]) \n",
    "mnb = mnb - harm\n",
    "out.loc[0] = pd.Series({\"features\": list(features_left), \"mnb\": mnb})\n",
    "\n",
    "for n_dropped in range(len(test_harms.keys())-1):\n",
    "    print(n_dropped)\n",
    "\n",
    "    mnb_per_drop = pd.DataFrame(columns = [\"droped_feature\", \"model_features\",\"mnb\"])\n",
    "    for i, droped_feature in enumerate(features_left):\n",
    "        #build a model with  the looped feature removed\n",
    "    \n",
    "        model_features = [i for i in features_left if not(i == droped_feature)]\n",
    "\n",
    "        # build a model with the selected features\n",
    "        logreg.fit(df_test[model_features], df_test[\"y\"])\n",
    "\n",
    "        ## Make predictions on the test set:\n",
    "        pred = logreg.predict_proba(df_test[model_features])\n",
    "\n",
    "        # auc\n",
    "        #auc = roc_auc_score(df_test[dependent],pred[:, 1])\n",
    "\n",
    "        # mnb\n",
    "        mnb = dcat.mean_net_benefit(df_test[dependent], pred[:, 1], n_thresh=100)['mnb']\n",
    "\n",
    "        #Include test harms\n",
    "        harm = sum([test_harms[i] for i in model_features]) \n",
    "\n",
    "        mnb = mnb - harm\n",
    "\n",
    "        mnb_per_drop.loc[i] = pd.Series({\"droped_feature\": droped_feature, \"model_features\": model_features, \"mnb\": mnb})\n",
    "        #print(mnb_per_drop)\n",
    "        #print(model_features, mnb)\n",
    "\n",
    "    #print(\"=====================\")\n",
    "    #print(mnb_per_drop)\n",
    "    #print(\"=====================\")\n",
    "    # drop the feature that results in the largest mean net benefit (i.e. has least impact on net benefit)\n",
    "    #print(mnb_per_drop)\n",
    "    excluded_feature = mnb_per_drop[mnb_per_drop['mnb']==mnb_per_drop['mnb'].max()]\n",
    "    #print(excluded_feature[\"droped_feature\"].to_list())\n",
    "    ef = excluded_feature[\"droped_feature\"].to_list()\n",
    "    features_left = [f for f in features_left if not f in ef]\n",
    "    mnb = excluded_feature[\"mnb\"].to_list()[0]\n",
    "    #update\n",
    "    out.loc[n_dropped+1] = pd.Series({\"features\": features_left, \"mnb\": mnb})\n",
    "\n",
    "\n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_stepwise_dcafs(train_data, test_data, model, harms_dict, dependent=\"y\"):\n",
    "\n",
    "    features_left = test_harms.keys()\n",
    "\n",
    "    # Initialize with full model\n",
    "    out = pd.DataFrame(columns = [\"features\", \"mnb\"])\n",
    "    model.fit(train_data[features_left], train_data[dependent])\n",
    "    pred = model.predict_proba(test_data[features_left])\n",
    "    mnb = dcat.mean_net_benefit(test_data[dependent], pred[:, 1], n_thresh=100)['mnb']\n",
    "    harm = sum([test_harms[i] for i in features_left]) \n",
    "    mnb = mnb - harm\n",
    "    out.loc[0] = pd.Series({\"features\": list(features_left), \"mnb\": mnb})\n",
    "\n",
    "    for n_dropped in range(len(test_harms.keys())-1):\n",
    "        #print(n_dropped)\n",
    "\n",
    "        mnb_per_drop = pd.DataFrame(columns = [\"droped_feature\", \"model_features\",\"mnb\"])\n",
    "        for i, droped_feature in enumerate(features_left):\n",
    "            #build a model with  the looped feature removed\n",
    "    \n",
    "            model_features = [i for i in features_left if not(i == droped_feature)]\n",
    "\n",
    "            # build a model with the selected features\n",
    "            model.fit(train_data[model_features], train_data[dependent])\n",
    "\n",
    "            ## Make predictions on the test set:\n",
    "            pred = model.predict_proba(test_data[model_features])\n",
    "\n",
    "            # auc\n",
    "            #auc = roc_auc_score(df_test[dependent],pred[:, 1])\n",
    "\n",
    "            # mnb\n",
    "            mnb = dcat.mean_net_benefit(test_data[dependent], pred[:, 1], n_thresh=100)['mnb']\n",
    "\n",
    "            #Include test harms\n",
    "            harm = sum([test_harms[i] for i in model_features]) \n",
    "\n",
    "            mnb = mnb - harm\n",
    "\n",
    "            mnb_per_drop.loc[i] = pd.Series({\"droped_feature\": droped_feature, \"model_features\": model_features, \"mnb\": mnb})\n",
    "\n",
    "\n",
    "        excluded_feature = mnb_per_drop[mnb_per_drop['mnb']==mnb_per_drop['mnb'].max()]\n",
    "    \n",
    "        ef = excluded_feature[\"droped_feature\"].to_list()\n",
    "        features_left = [f for f in features_left if not f in ef]\n",
    "        mnb = excluded_feature[\"mnb\"].to_list()[0]\n",
    "        out.loc[n_dropped+1] = pd.Series({\"features\": features_left, \"mnb\": mnb})\n",
    "\n",
    "\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mnb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[x0, x1, x2, x3, x4]</td>\n",
       "      <td>0.142756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[x0, x1, x2, x4]</td>\n",
       "      <td>0.180113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[x0, x1, x4]</td>\n",
       "      <td>0.212192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[x1, x4]</td>\n",
       "      <td>0.219324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[x1]</td>\n",
       "      <td>0.209659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               features       mnb\n",
       "0  [x0, x1, x2, x3, x4]  0.142756\n",
       "1      [x0, x1, x2, x4]  0.180113\n",
       "2          [x0, x1, x4]  0.212192\n",
       "3              [x1, x4]  0.219324\n",
       "4                  [x1]  0.209659"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_harms = {\"x0\": 0.0, \"x1\": 0.015, \"x2\": 0.03, \"x3\": 0.045, \"x4\": 0.06 }\n",
    "\n",
    "test = backward_stepwise_dcafs(df_train, df_test, logreg, test_harms)\n",
    "\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
